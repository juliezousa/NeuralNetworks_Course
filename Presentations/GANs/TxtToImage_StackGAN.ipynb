{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d155ad0",
   "metadata": {},
   "source": [
    "# Creditos\n",
    "Aqui o repositorio original do codigo: https://github.com/AarohiSingla/StackGAN\n",
    "Uma explição do funcionamento do codigo pela autora: https://www.youtube.com/watch?v=ye6pYwBQQL4\n",
    "\n",
    "# Pastas\n",
    "Neste codigo se precisam das seguintes pastas em seu diretorio atual:\n",
    "-weights (para salvar os pesos do modelo depois do training)\n",
    "-test (images geradar pela primer gerador)\n",
    "-results_stage2 (images geradas pelo segundo gerador, o que é a salida final do modelo)\n",
    "\n",
    "\n",
    "# Dados\n",
    "O dataset usado aqui pode-se descargar de http://www.vision.caltech.edu/visipedia/CUB-200-2011.html\n",
    "\n",
    "# Gerador de Embeddings pre-treinados\n",
    "\n",
    "https://drive.google.com/file/d/0B3y_msrWZaXLT1BZdVdycDY5TEE/view?resourcekey=0-sZrhftoEfdvHq6MweAeCjA ou https://github.com/hanzhanggit/StackGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02201435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, ReLU, Activation\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Concatenate, Dense, concatenate\n",
    "from tensorflow.keras.layers import Flatten, Lambda, Reshape, ZeroPadding2D, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a1a412",
   "metadata": {},
   "source": [
    "# Conditioning Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d820a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditioning_augmentation(x):\n",
    "    mean = x[:, :128]\n",
    "    log_sigma = x[:, 128:]\n",
    "    stddev = tf.math.exp(log_sigma)\n",
    "    epsilon = K.random_normal(shape=K.constant((mean.shape[1], ), dtype='int32'))\n",
    "    c = mean + stddev * epsilon\n",
    "    return c\n",
    "\n",
    "def build_ca_network():\n",
    "    \"\"\"Builds the conditioning augmentation network\"\"\"\n",
    "    input_layer1 = Input(shape=(1024,)) #size of the vocabulary in the text data\n",
    "    mls = Dense(256)(input_layer1)\n",
    "    mls = LeakyReLU(alpha=0.2)(mls)\n",
    "    ca = Lambda(conditioning_augmentation)(mls)\n",
    "    return Model(inputs=[input_layer1], outputs=[ca]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d0079",
   "metadata": {},
   "source": [
    "StackGAN:Definição da Arquitetura do primer gerador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80caaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpSamplingBlock(x, num_kernels):\n",
    "    \n",
    "    x = UpSampling2D(size=(2,2))(x)\n",
    "    x = Conv2D(num_kernels, kernel_size=(3,3), padding='same', strides=1, use_bias=False,kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x) #prevent from mode collapse\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_stage1_generator():\n",
    "\n",
    "    input_layer1 = Input(shape=(1024,))\n",
    "    ca = Dense(256)(input_layer1)\n",
    "    ca = LeakyReLU(alpha=0.2)(ca)\n",
    "\n",
    "    # Obtain the conditioned text\n",
    "    c = Lambda(conditioning_augmentation)(ca)\n",
    "\n",
    "    input_layer2 = Input(shape=(100,))\n",
    "    concat = Concatenate(axis=1)([c, input_layer2]) \n",
    "    x = Dense(16384, use_bias=False)(concat) \n",
    "\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Reshape((4, 4, 1024), input_shape=(16384,))(x)\n",
    "\n",
    "\n",
    "    x = UpSamplingBlock(x, 512) \n",
    "    x = UpSamplingBlock(x, 256)\n",
    "    x = UpSamplingBlock(x, 128)\n",
    "    x = UpSamplingBlock(x, 64)   # upsampled our image to 64*64*3 \n",
    "\n",
    "    x = Conv2D(3, kernel_size=3, padding='same', strides=1, use_bias=False,kernel_initializer='he_uniform')(x)\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    stage1_gen = Model(inputs=[input_layer1, input_layer2], outputs=[x, ca]) \n",
    "    return stage1_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1a0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_stage1_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c07b8",
   "metadata": {},
   "source": [
    "StackGAN:Definição da Arquitetura do primer discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e6debc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(x, num_kernels, kernel_size=(4,4), strides=2, activation=True):\n",
    "\n",
    "    x = Conv2D(num_kernels, kernel_size=kernel_size, padding='same', strides=strides, use_bias=False,kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "    \n",
    "    if activation:\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_embedding_compressor():\n",
    "    \"\"\"Build embedding compressor model\n",
    "    \"\"\"\n",
    "    input_layer1 = Input(shape=(1024,)) \n",
    "    x = Dense(128)(input_layer1)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    model = Model(inputs=[input_layer1], outputs=[x])\n",
    "    return model\n",
    "\n",
    "# the discriminator is fed with two inputs, the feature from Generator and the text embedding\n",
    "def build_stage1_discriminator():\n",
    "\n",
    "    input_layer1 = Input(shape=(64, 64, 3))  \n",
    "\n",
    "    x = Conv2D(64, kernel_size=(4,4), strides=2, padding='same', use_bias=False,kernel_initializer='he_uniform')(input_layer1)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = ConvBlock(x, 128)\n",
    "    x = ConvBlock(x, 256)\n",
    "    x = ConvBlock(x, 512)\n",
    "\n",
    "    # Obtain the compressed and spatially replicated text embedding\n",
    "    input_layer2 = Input(shape=(4, 4, 128)) #2nd input to discriminator, text embedding\n",
    "    concat = concatenate([x, input_layer2])\n",
    "\n",
    "    x1 = Conv2D(512, kernel_size=(1,1), padding='same', strides=1, use_bias=False,kernel_initializer='he_uniform')(concat)\n",
    "    x1 = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Flatten and add a FC layer to predict.\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = Dense(1)(x1)\n",
    "    x1 = Activation('sigmoid')(x1)\n",
    "\n",
    "    stage1_dis = Model(inputs=[input_layer1, input_layer2], outputs=[x1])  \n",
    "    return stage1_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d584bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_stage1_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b652d8",
   "metadata": {},
   "source": [
    "# StackGAN: Primeira parte\n",
    "Configuração do sistema adversario entre o primer gerador e o primer discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "593f34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adversarial(generator_model, discriminator_model):\n",
    "\t\"\"\"Stage 1 Adversarial model.\n",
    "\n",
    "\tArgs:\n",
    "\t\tgenerator_model: Stage 1 Generator Model\n",
    "\t\tdiscriminator_model: Stage 1 Discriminator Model\n",
    "\n",
    "\tReturns:\n",
    "\t\tAdversarial Model.\n",
    "\t\"\"\"\n",
    "\tinput_layer1 = Input(shape=(1024,))  \n",
    "\tinput_layer2 = Input(shape=(100,)) \n",
    "\tinput_layer3 = Input(shape=(4, 4, 128)) \n",
    "\n",
    "\tx, ca = generator_model([input_layer1, input_layer2]) #text,noise\n",
    "\n",
    "\tdiscriminator_model.trainable = False \n",
    "\n",
    "\tprobabilities = discriminator_model([x, input_layer3]) \n",
    "\tadversarial_model = Model(inputs=[input_layer1, input_layer2, input_layer3], outputs=[probabilities, ca])\n",
    "\treturn adversarial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67cdfc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ganstage1 = build_adversarial(generator, discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac773bf5",
   "metadata": {},
   "source": [
    "Funções para o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1982ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_prefix():\n",
    "\tcheckpoint_dir = './training_checkpoints'\n",
    "\tcheckpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "\n",
    "\treturn checkpoint_prefix\n",
    "\n",
    "def adversarial_loss(y_true, y_pred):\n",
    "\tmean = y_pred[:, :128]\n",
    "\tls = y_pred[:, 128:]\n",
    "\tloss = -ls + 0.5 * (-1 + tf.math.exp(2.0 * ls) + tf.math.square(mean))\n",
    "\tloss = K.mean(loss)\n",
    "\treturn loss\n",
    "\n",
    "def normalize(input_image, real_image):\n",
    "\tinput_image = (input_image / 127.5) - 1\n",
    "\treal_image = (real_image / 127.5) - 1\n",
    "\n",
    "\treturn input_image, real_image\n",
    "\n",
    "def load_class_ids_filenames(class_id_path, filename_path):\n",
    "\twith open(class_id_path, 'rb') as file:\n",
    "\t\tclass_id = pickle.load(file, encoding='latin1')\n",
    "\n",
    "\twith open(filename_path, 'rb') as file:\n",
    "\t\tfilename = pickle.load(file, encoding='latin1')\n",
    "\n",
    "\treturn class_id, filename\n",
    "\n",
    "def load_text_embeddings(text_embeddings):\n",
    "\twith open(text_embeddings, 'rb') as file:\n",
    "\t\tembeds = pickle.load(file, encoding='latin1')\n",
    "\t\tembeds = np.array(embeds)\n",
    "\n",
    "\treturn embeds\n",
    "\n",
    "def load_bbox(data_path):\n",
    "\tbbox_path = data_path + '/bounding_boxes.txt'\n",
    "\timage_path = data_path + '/images.txt'\n",
    "\tbbox_df = pd.read_csv(bbox_path, delim_whitespace=True, header=None).astype(int)\n",
    "\tfilename_df = pd.read_csv(image_path, delim_whitespace=True, header=None)\n",
    "\n",
    "\tfilenames = filename_df[1].tolist()\n",
    "\tbbox_dict = {i[:-4]:[] for i in filenames[:2]}\n",
    "\n",
    "\tfor i in range(0, len(filenames)):\n",
    "\t\tbbox = bbox_df.iloc[i][1:].tolist()\n",
    "\t\tdict_key = filenames[i][:-4]\n",
    "\t\tbbox_dict[dict_key] = bbox\n",
    "\n",
    "\treturn bbox_dict\n",
    "\n",
    "def load_images(image_path, bounding_box, size):\n",
    "\t\"\"\"Crops the image to the bounding box and then resizes it.\n",
    "\t\"\"\"\n",
    "\timage = Image.open(image_path).convert('RGB')\n",
    "\tw, h = image.size\n",
    "\tif bounding_box is not None:\n",
    "\t\tr = int(np.maximum(bounding_box[2], bounding_box[3]) * 0.75)\n",
    "\t\tc_x = int((bounding_box[0] + bounding_box[2]) / 2)\n",
    "\t\tc_y = int((bounding_box[1] + bounding_box[3]) / 2)\n",
    "\t\ty1 = np.maximum(0, c_y - r)\n",
    "\t\ty2 = np.minimum(h, c_y + r)\n",
    "\t\tx1 = np.maximum(0, c_x - r)\n",
    "\t\tx2 = np.minimum(w, c_x + r)\n",
    "\t\timage = image.crop([x1, y1, x2, y2])\n",
    "\n",
    "\timage = image.resize(size, PIL.Image.BILINEAR)\n",
    "\treturn image\n",
    "\n",
    "def load_data(filename_path, class_id_path, dataset_path, embeddings_path, size):\n",
    "\t\"\"\"Loads the Dataset.\n",
    "\t\"\"\"\n",
    "\tdata_dir = \"D:/1-pipelined_topics/GAN_texttoimage/birds_implementation/birds\"\n",
    "\ttrain_dir = data_dir + \"/train\"\n",
    "\ttest_dir = data_dir + \"/test\"\n",
    "\tembeddings_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "\tembeddings_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "\tfilename_path_train = train_dir + \"/filenames.pickle\"\n",
    "\tfilename_path_test = test_dir + \"/filenames.pickle\"\n",
    "\tclass_id_path_train = train_dir + \"/class_info.pickle\"\n",
    "\tclass_id_path_test = test_dir + \"/class_info.pickle\"\n",
    "\tdataset_path = \"D:/1-pipelined_topics/GAN_texttoimage/birds_implementation/CUB_200_2011\"\n",
    "\tclass_id, filenames = load_class_ids_filenames(class_id_path, filename_path)\n",
    "\tembeddings = load_text_embeddings(embeddings_path)\n",
    "\tbbox_dict = load_bbox(dataset_path)\n",
    "\n",
    "\tx, y, embeds = [], [], []\n",
    "\n",
    "\tfor i, filename in enumerate(filenames):\n",
    "\t\tbbox = bbox_dict[filename]\n",
    "\n",
    "\t\ttry:\t\n",
    "\t\t\timage_path = f'{dataset_path}/images/{filename}.jpg'\n",
    "\t\t\timage = load_images(image_path, bbox, size)\n",
    "\t\t\te = embeddings[i, :, :]\n",
    "\t\t\tembed_index = np.random.randint(0, e.shape[0] - 1)\n",
    "\t\t\tembed = e[embed_index, :]\n",
    "\n",
    "\t\t\tx.append(np.array(image))\n",
    "\t\t\ty.append(class_id[i])\n",
    "\t\t\tembeds.append(embed)\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f'{e}')\n",
    "\t\n",
    "\tx = np.array(x)\n",
    "\ty = np.array(y)\n",
    "\tembeds = np.array(embeds)\n",
    "\t\n",
    "\treturn x, y, embeds\n",
    "\n",
    "def save_image(file, save_path):\n",
    "\t\"\"\"Saves the image at the specified file path.\n",
    "\t\"\"\"\n",
    "\timage = plt.figure()\n",
    "\tax = image.add_subplot(1,1,1)\n",
    "\tax.imshow(file)\n",
    "\tax.axis(\"off\")\n",
    "\tplt.savefig(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abf7f46",
   "metadata": {},
   "source": [
    "# Treinamento da primera etapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackGanStage1(object):\n",
    "  \"\"\"StackGAN Stage 1 class.\"\"\"\n",
    "\n",
    "  data_dir = \"D:/1-pipelined_topics/GAN_texttoimage/birds_implementation/birds\"\n",
    "  train_dir = data_dir + \"/train\"\n",
    "  test_dir = data_dir + \"/test\"\n",
    "  embeddings_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "  embeddings_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "  filename_path_train = train_dir + \"/filenames.pickle\"\n",
    "  filename_path_test = test_dir + \"/filenames.pickle\"\n",
    "  class_id_path_train = train_dir + \"/class_info.pickle\"\n",
    "  class_id_path_test = test_dir + \"/class_info.pickle\"\n",
    "  dataset_path = \"D:/1-pipelined_topics/GAN_texttoimage/birds_implementation/CUB_200_2011\"\n",
    "  def __init__(self, epochs=500, z_dim=100, batch_size=64, enable_function=True, stage1_generator_lr=0.0002, stage1_discriminator_lr=0.0002):\n",
    "\t  self.epochs = epochs\n",
    "\t  self.z_dim = z_dim\n",
    "\t  self.enable_function = enable_function\n",
    "\t  self.stage1_generator_lr = stage1_generator_lr\n",
    "\t  self.stage1_discriminator_lr = stage1_discriminator_lr\n",
    "\t  self.image_size = 64\n",
    "\t  self.conditioning_dim = 128\n",
    "\t  self.batch_size = batch_size\n",
    "        \n",
    "\t  self.stage1_generator_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\t  self.stage1_discriminator_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "        \n",
    "\t  self.stage1_generator = build_stage1_generator()\n",
    "\t  self.stage1_generator.compile(loss='mse', optimizer=self.stage1_generator_optimizer)\n",
    "\n",
    "\t  self.stage1_discriminator = build_stage1_discriminator()\n",
    "\t  self.stage1_discriminator.compile(loss='binary_crossentropy', optimizer=self.stage1_discriminator_optimizer)\n",
    "\n",
    "\t  self.ca_network = build_ca_network()\n",
    "\t  self.ca_network.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "\t  self.embedding_compressor = build_embedding_compressor()\n",
    "\t  self.embedding_compressor.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "\t  self.stage1_adversarial = build_adversarial(self.stage1_generator, self.stage1_discriminator)\n",
    "\t  self.stage1_adversarial.compile(loss=['binary_crossentropy', adversarial_loss], loss_weights=[1, 2.0], optimizer=self.stage1_generator_optimizer)\n",
    "\n",
    "\t  self.checkpoint1 = tf.train.Checkpoint(\n",
    "        \tgenerator_optimizer=self.stage1_generator_optimizer,\n",
    "        \tdiscriminator_optimizer=self.stage1_discriminator_optimizer,\n",
    "        \tgenerator=self.stage1_generator,\n",
    "        \tdiscriminator=self.stage1_discriminator)\n",
    "\n",
    "  def visualize_stage1(self):\n",
    "\t  \"\"\"Running Tensorboard visualizations.\n",
    "\t\t\"\"\"\n",
    "\t  tb = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
    "\t  tb.set_model(self.stage1_generator)\n",
    "\t  tb.set_model(self.stage1_discriminator)\n",
    "\t  tb.set_model(self.ca_network)\n",
    "\t  tb.set_model(self.embedding_compressor)\n",
    "\n",
    "  def train_stage1(self):\n",
    "\t  \"\"\"Trains the stage1 StackGAN.\n",
    "    \"\"\"\n",
    "\t  x_train, y_train, train_embeds = load_data(filename_path=filename_path_train, class_id_path=class_id_path_train,\n",
    "      dataset_path=dataset_path, embeddings_path=embeddings_path_train, size=(64, 64))\n",
    "\n",
    "\t  x_test, y_test, test_embeds = load_data(filename_path=filename_path_test, class_id_path=class_id_path_test, \n",
    "      dataset_path=dataset_path, embeddings_path=embeddings_path_test, size=(64, 64))\n",
    "\n",
    "\t  real = np.ones((self.batch_size, 1), dtype='float') * 0.9\n",
    "\t  fake = np.zeros((self.batch_size, 1), dtype='float') * 0.1\n",
    "\n",
    "\t  for epoch in range(self.epochs):\n",
    "\t\t  print(f'Epoch: {epoch}')\n",
    "\n",
    "\t\t  gen_loss = []\n",
    "\t\t  dis_loss = []\n",
    "\n",
    "\t\t  num_batches = int(x_train.shape[0] / self.batch_size)\n",
    "\n",
    "\t\t  for i in range(num_batches):\n",
    "\n",
    "\t\t    latent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
    "\t\t    embedding_text = train_embeds[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\t\t    compressed_embedding = self.embedding_compressor.predict_on_batch(embedding_text)\n",
    "\t\t    compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, 128))\n",
    "\t\t    compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
    "\n",
    "\t\t    image_batch = x_train[i * self.batch_size:(i+1) * self.batch_size]\n",
    "\t\t    image_batch = (image_batch - 127.5) / 127.5\n",
    "\n",
    "\t\t    gen_images, _ = self.stage1_generator.predict([embedding_text, latent_space])\n",
    "\n",
    "\t\t    discriminator_loss = self.stage1_discriminator.train_on_batch([image_batch, compressed_embedding], \n",
    "\t\t\t\t\tnp.reshape(real, (self.batch_size, 1)))\n",
    "\n",
    "\t\t    discriminator_loss_gen = self.stage1_discriminator.train_on_batch([gen_images, compressed_embedding],\n",
    "\t\t\t\t\tnp.reshape(fake, (self.batch_size, 1)))\n",
    "\n",
    "\t\t    discriminator_loss_wrong = self.stage1_discriminator.train_on_batch([gen_images[: self.batch_size-1], compressed_embedding[1:]], \n",
    "\t\t\t\t\tnp.reshape(fake[1:], (self.batch_size-1, 1)))\n",
    "\n",
    "\t\t    # Discriminator loss\n",
    "\t\t    d_loss = 0.5 * np.add(discriminator_loss, 0.5 * np.add(discriminator_loss_gen, discriminator_loss_wrong))\n",
    "\t\t    dis_loss.append(d_loss)\n",
    "\n",
    "\t\t    print(f'Discriminator Loss: {d_loss}')\n",
    "\n",
    "\t\t    # Generator loss\n",
    "\t\t    g_loss = self.stage1_adversarial.train_on_batch([embedding_text, latent_space, compressed_embedding],\n",
    "\t\t\t\t\t[K.ones((self.batch_size, 1)) * 0.9, K.ones((self.batch_size, 256)) * 0.9])\n",
    "\n",
    "\t\t    print(f'Generator Loss: {g_loss}')\n",
    "\t\t    gen_loss.append(g_loss)\n",
    "\n",
    "\t\t    if epoch % 5 == 0:\n",
    "\t\t\t\t    latent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
    "\t\t\t\t    embedding_batch = test_embeds[0 : self.batch_size]\n",
    "\t\t\t\t    gen_images, _ = self.stage1_generator.predict_on_batch([embedding_batch, latent_space])\n",
    "\n",
    "\t\t\t\t    for i, image in enumerate(gen_images[:10]):\n",
    "\t\t\t\t        save_image(image, f'test/gen_1_{epoch}_{i}')\n",
    "\n",
    "\t\t    if epoch % 25 == 0:\n",
    "\t\t      self.stage1_generator.save_weights('weights/stage1_gen.h5')\n",
    "\t\t      self.stage1_discriminator.save_weights(\"weights/stage1_disc.h5\")\n",
    "\t\t      self.ca_network.save_weights('weights/stage1_ca.h5')\n",
    "\t\t      self.embedding_compressor.save_weights('weights/stage1_embco.h5')\n",
    "\t\t      self.stage1_adversarial.save_weights('weights/stage1_adv.h5')      \n",
    "\n",
    "\t  self.stage1_generator.save_weights('weights/stage1_gen.h5')\n",
    "\t  self.stage1_discriminator.save_weights(\"weights/stage1_disc.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6bc0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1 = StackGanStage1()\n",
    "stage1.train_stage1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0850a0",
   "metadata": {},
   "source": [
    "StackGAN:Definição da Arquitetura do segundo gerador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_along_dims(inputs):\n",
    "\t\"\"\"Joins the conditioned text with the encoded image along the dimensions.\n",
    "\n",
    "\tArgs:\n",
    "\t\tinputs: consisting of conditioned text and encoded images as [c,x].\n",
    "\n",
    "\tReturns:\n",
    "\t\tJoint block along the dimensions.\n",
    "\t\"\"\"\n",
    "\tc = inputs[0]\n",
    "\tx = inputs[1]\n",
    "\n",
    "\tc = K.expand_dims(c, axis=1)\n",
    "\tc = K.expand_dims(c, axis=1)\n",
    "\tc = K.tile(c, [1, 16, 16, 1])\n",
    "\treturn K.concatenate([c, x], axis = 3)\n",
    "\n",
    "def residual_block(input):\n",
    "\t\"\"\"Residual block with plain identity connections.\n",
    "\n",
    "\tArgs:\n",
    "\t\tinputs: input layer or an encoded layer\n",
    "\n",
    "\tReturns:\n",
    "\t\tLayer with computed identity mapping.\n",
    "\t\"\"\"\n",
    "\tx = Conv2D(512, kernel_size=(3,3), padding='same', use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(input)\n",
    "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "\tx = ReLU()(x)\n",
    "\t\n",
    "\tx = Conv2D(512, kernel_size=(3,3), padding='same', use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "\t\n",
    "\tx = add([x, input])\n",
    "\tx = ReLU()(x)\n",
    "\n",
    "\treturn x\n",
    "\n",
    "def build_stage2_generator():\n",
    "\t\"\"\"Build the Stage 2 Generator Network using the conditioning text and images from stage 1.\n",
    "\n",
    "\tReturns:\n",
    "\t\tStage 2 Generator Model for StackGAN.\n",
    "\t\"\"\"\n",
    "\tinput_layer1 = Input(shape=(1024,))\n",
    "\tinput_images = Input(shape=(64, 64, 3))\n",
    "\n",
    "\t# Conditioning Augmentation\n",
    "\tca = Dense(256)(input_layer1)\n",
    "\tmls = LeakyReLU(alpha=0.2)(ca)\n",
    "\tc = Lambda(conditioning_augmentation)(mls)\n",
    "\n",
    "\t# Downsampling block\n",
    "\tx = ZeroPadding2D(padding=(1,1))(input_images)\n",
    "\tx = Conv2D(128, kernel_size=(3,3), strides=1, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = ReLU()(x)\n",
    "\n",
    "\tx = ZeroPadding2D(padding=(1,1))(x)\n",
    "\tx = Conv2D(256, kernel_size=(4,4), strides=2, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "\tx = ReLU()(x)\n",
    "\n",
    "\tx = ZeroPadding2D(padding=(1,1))(x)\n",
    "\tx = Conv2D(512, kernel_size=(4,4), strides=2, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "\tx = ReLU()(x)\n",
    "\n",
    "\t# Concatenate text conditioning block with the encoded image\n",
    "\tconcat = concat_along_dims([c, x])\n",
    "\n",
    "\t# Residual Blocks\n",
    "\tx = ZeroPadding2D(padding=(1,1))(concat)\n",
    "\tx = Conv2D(512, kernel_size=(3,3), use_bias=False, kernel_initializer='he_uniform')(x)\n",
    "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "\tx = ReLU()(x)\n",
    "\n",
    "\tx = residual_block(x)\n",
    "\tx = residual_block(x)\n",
    "\tx = residual_block(x)\n",
    "\tx = residual_block(x)\n",
    "\n",
    "\t# Upsampling Blocks\n",
    "\tx = UpSamplingBlock(x, 512)\n",
    "\tx = UpSamplingBlock(x, 256)\n",
    "\tx = UpSamplingBlock(x, 128)\n",
    "\tx = UpSamplingBlock(x, 64)\n",
    "\n",
    "\tx = Conv2D(3, kernel_size=(3,3), padding='same', use_bias=False, kernel_initializer='he_uniform')(x)\n",
    "\tx = Activation('tanh')(x)\n",
    "\t\n",
    "\tstage2_gen = Model(inputs=[input_layer1, input_images], outputs=[x, mls])\n",
    "\treturn stage2_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19eb247",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_stage2 = build_stage2_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc54fc",
   "metadata": {},
   "source": [
    "StackGAN:Definição da Arquitetura do segundo discriminador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5c064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stage2_discriminator():\n",
    "\t\"\"\"Builds the Stage 2 Discriminator that uses the 256x256 resolution images from the generator\n",
    "\tand the compressed and spatially replicated embeddings.\n",
    "\n",
    "\tReturns:\n",
    "\t\tStage 2 Discriminator Model for StackGAN.\n",
    "\t\"\"\"\n",
    "\tinput_layer1 = Input(shape=(256, 256, 3))\n",
    "\n",
    "\tx = Conv2D(64, kernel_size=(4,4), padding='same', strides=2, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(input_layer1)\n",
    "\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\tx = ConvBlock(x, 128)\n",
    "\tx = ConvBlock(x, 256)\n",
    "\tx = ConvBlock(x, 512)\n",
    "\tx = ConvBlock(x, 1024)\n",
    "\tx = ConvBlock(x, 2048)\n",
    "\tx = ConvBlock(x, 1024, (1,1), 1)\n",
    "\tx = ConvBlock(x, 512, (1,1), 1, False)\n",
    "\n",
    "\tx1 = ConvBlock(x, 128, (1,1), 1)\n",
    "\tx1 = ConvBlock(x1, 128, (3,3), 1)\n",
    "\tx1 = ConvBlock(x1, 512, (3,3), 1, False)\n",
    "\n",
    "\tx2 = add([x, x1])\n",
    "\tx2 = LeakyReLU(alpha=0.2)(x2)\n",
    "\n",
    "\t# Concatenate compressed and spatially replicated embedding\n",
    "\tinput_layer2 = Input(shape=(4, 4, 128))\n",
    "\tconcat = concatenate([x2, input_layer2])\n",
    "\n",
    "\tx3 = Conv2D(512, kernel_size=(1,1), strides=1, padding='same', kernel_initializer='he_uniform')(concat)\n",
    "\tx3 = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x3)\n",
    "\tx3 = LeakyReLU(alpha=0.2)(x3)\n",
    "\n",
    "\t# Flatten and add a FC layer\n",
    "\tx3 = Flatten()(x3)\n",
    "\tx3 = Dense(1)(x3)\n",
    "\tx3 = Activation('sigmoid')(x3)\n",
    "\n",
    "\tstage2_dis = Model(inputs=[input_layer1, input_layer2], outputs=[x3])\n",
    "\treturn stage2_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e0c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_stage2 = build_stage2_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9598c324",
   "metadata": {},
   "source": [
    "# StackGAN: Segunda parte\n",
    "Configuração do sistema adversario entre o segundo gerador e o segundo discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ce753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage2_adversarial_network(stage2_disc, stage2_gen, stage1_gen):\n",
    "\t\"\"\"Stage 2 Adversarial Network.\n",
    "\n",
    "\tArgs:\n",
    "\t\tstage2_disc: Stage 2 Discriminator Model.\n",
    "\t\tstage2_gen: Stage 2 Generator Model.\n",
    "\t\tstage1_gen: Stage 1 Generator Model.\n",
    "\n",
    "\tReturns:\n",
    "\t\tStage 2 Adversarial network.\n",
    "\t\"\"\"\n",
    "\tconditioned_embedding = Input(shape=(1024, ))\n",
    "\tlatent_space = Input(shape=(100, ))\n",
    "\tcompressed_replicated = Input(shape=(4, 4, 128))\n",
    "    \n",
    "\t#the discriminator is trained separately and stage1_gen already trained, and this is the reason why we freeze its layers by setting the property trainable=false\n",
    "\tinput_images, ca = stage1_gen([conditioned_embedding, latent_space])\n",
    "\tstage2_disc.trainable = False\n",
    "\tstage1_gen.trainable = False\n",
    "\n",
    "\timages, ca2 = stage2_gen([conditioned_embedding, input_images])\n",
    "\tprobability = stage2_disc([images, compressed_replicated])\n",
    "\n",
    "\treturn Model(inputs=[conditioned_embedding, latent_space, compressed_replicated],\n",
    "\t\toutputs=[probability, ca2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbad4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_stage2 = stage2_adversarial_network(discriminator_stage2, generator_stage2, generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05ab9ee",
   "metadata": {},
   "source": [
    "# Treinamento da segunda etapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a79418",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackGanStage2(object):\n",
    "\t\"\"\"StackGAN Stage 2 class.\n",
    "\n",
    "\tArgs:\n",
    "\t\tepochs: Number of epochs\n",
    "\t\tz_dim: Latent space dimensions\n",
    "\t\tbatch_size: Batch Size\n",
    "\t\tenable_function: If True, training function is decorated with tf.function\n",
    "\t\tstage2_generator_lr: Learning rate for stage 2 generator\n",
    "\t\tstage2_discriminator_lr: Learning rate for stage 2 discriminator\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, epochs=500, z_dim=100, batch_size=64, enable_function=True, stage2_generator_lr=0.0002, stage2_discriminator_lr=0.0002):\n",
    "\t\tself.epochs = epochs\n",
    "\t\tself.z_dim = z_dim\n",
    "\t\tself.enable_function = enable_function\n",
    "\t\tself.stage1_generator_lr = stage2_generator_lr\n",
    "\t\tself.stage1_discriminator_lr = stage2_discriminator_lr\n",
    "\t\tself.low_image_size = 64\n",
    "\t\tself.high_image_size = 256\n",
    "\t\tself.conditioning_dim = 128\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.stage2_generator_optimizer = Adam(lr=stage2_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\t\tself.stage2_discriminator_optimizer = Adam(lr=stage2_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\t\tself.stage1_generator = build_stage1_generator()\n",
    "\t\tself.stage1_generator.compile(loss='binary_crossentropy', optimizer=self.stage2_generator_optimizer)\n",
    "\t\tself.stage1_generator.load_weights('weights/stage1_gen.h5')\n",
    "\t\tself.stage2_generator = build_stage2_generator()\n",
    "\t\tself.stage2_generator.compile(loss='binary_crossentropy', optimizer=self.stage2_generator_optimizer)\n",
    "\n",
    "\t\tself.stage2_discriminator = build_stage2_discriminator()\n",
    "\t\tself.stage2_discriminator.compile(loss='binary_crossentropy', optimizer=self.stage2_discriminator_optimizer)\n",
    "\n",
    "\t\tself.ca_network = build_ca_network()\n",
    "\t\tself.ca_network.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "\t\tself.embedding_compressor = build_embedding_compressor()\n",
    "\t\tself.embedding_compressor.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "\t\tself.stage2_adversarial = stage2_adversarial_network(self.stage2_discriminator, self.stage2_generator, self.stage1_generator)\n",
    "\t\tself.stage2_adversarial.compile(loss=['binary_crossentropy', adversarial_loss], loss_weights=[1, 2.0], optimizer=self.stage2_generator_optimizer)\t\n",
    "\n",
    "\t\tself.checkpoint2 = tf.train.Checkpoint(\n",
    "        \tgenerator_optimizer=self.stage2_generator_optimizer,\n",
    "        \tdiscriminator_optimizer=self.stage2_discriminator_optimizer,\n",
    "        \tgenerator=self.stage2_generator,\n",
    "        \tdiscriminator=self.stage2_discriminator,\n",
    "        \tgenerator1=self.stage1_generator)\n",
    "\n",
    "\tdef visualize_stage2(self):\n",
    "\t\t\"\"\"Running Tensorboard visualizations.\n",
    "\t\t\"\"\"\n",
    "\t\ttb = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
    "\t\ttb.set_model(self.stage2_generator)\n",
    "\t\ttb.set_model(self.stage2_discriminator)\n",
    "\n",
    "\tdef train_stage2(self):\n",
    "\t\t\"\"\"Trains Stage 2 StackGAN.\n",
    "\t\t\"\"\"\n",
    "\t\tx_high_train, y_high_train, high_train_embeds = load_data(filename_path=filename_path_train, class_id_path=class_id_path_train,\n",
    "      dataset_path=dataset_path, embeddings_path=embeddings_path_train, size=(256, 256))\n",
    "\n",
    "\t\tx_high_test, y_high_test, high_test_embeds = load_data(filename_path=filename_path_test, class_id_path=class_id_path_test, \n",
    "      dataset_path=dataset_path, embeddings_path=embeddings_path_test, size=(256, 256))\n",
    "\n",
    "\t\tx_low_train, y_low_train, low_train_embeds = load_data(filename_path=filename_path_train, class_id_path=class_id_path_train,\n",
    "      dataset_path=dataset_path, embeddings_path=embeddings_path_train, size=(64, 64))\n",
    "\n",
    "\t\tx_low_test, y_low_test, low_test_embeds = load_data(filename_path=filename_path_test, class_id_path=class_id_path_test, \n",
    "      dataset_path=dataset_path, embeddings_path=embeddings_path_test, size=(64, 64))\n",
    "\n",
    "\t\treal = np.ones((self.batch_size, 1), dtype='float') * 0.9\n",
    "\t\tfake = np.zeros((self.batch_size, 1), dtype='float') * 0.1\n",
    "\n",
    "\t\tfor epoch in range(self.epochs):\n",
    "\t\t\tprint(f'Epoch: {epoch}')\n",
    "\n",
    "\t\t\tgen_loss = []\n",
    "\t\t\tdisc_loss = []\n",
    "\n",
    "\t\t\tnum_batches = int(x_high_train.shape[0] / self.batch_size)\n",
    "\n",
    "\t\t\tfor i in range(num_batches):\n",
    "\n",
    "\t\t\t\tlatent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
    "\t\t\t\tembedding_text = high_train_embeds[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\t\t\t\tcompressed_embedding = self.embedding_compressor.predict_on_batch(embedding_text)\n",
    "\t\t\t\tcompressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, self.conditioning_dim))\n",
    "\t\t\t\tcompressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
    "\n",
    "\t\t\t\timage_batch = x_high_train[i * self.batch_size:(i+1) * self.batch_size]\n",
    "\t\t\t\timage_batch = (image_batch - 127.5) / 127.5\n",
    "\t\t\t\t\n",
    "\t\t\t\tlow_res_fakes, _ = self.stage1_generator.predict([embedding_text, latent_space], verbose=3)\n",
    "\t\t\t\thigh_res_fakes, _ = self.stage2_generator.predict([embedding_text, low_res_fakes], verbose=3)\n",
    "\n",
    "\t\t\t\tdiscriminator_loss = self.stage2_discriminator.train_on_batch([image_batch, compressed_embedding],\n",
    "\t\t\t\t\tnp.reshape(real, (self.batch_size, 1)))\n",
    "\n",
    "\t\t\t\tdiscriminator_loss_gen = self.stage2_discriminator.train_on_batch([high_res_fakes, compressed_embedding],\n",
    "\t\t\t\t\tnp.reshape(fake, (self.batch_size, 1)))\n",
    "\n",
    "\t\t\t\tdiscriminator_loss_fake = self.stage2_discriminator.train_on_batch([image_batch[:(self.batch_size-1)], compressed_embedding[1:]],\n",
    "\t\t\t\t\tnp.reshape(fake[1:], (self.batch_size - 1, 1)))\n",
    "\n",
    "\t\t\t\td_loss = 0.5 * np.add(discriminator_loss, 0.5 * np.add(discriminator_loss_gen, discriminator_loss_fake))\n",
    "\t\t\t\tdisc_loss.append(d_loss)\n",
    "\n",
    "\t\t\t\tprint(f'Discriminator Loss: {d_loss}')\n",
    "\n",
    "\t\t\t\tg_loss = self.stage2_adversarial.train_on_batch([embedding_text, latent_space, compressed_embedding],\n",
    "\t\t\t\t\t[K.ones((self.batch_size, 1)) * 0.9, K.ones((self.batch_size, 256)) * 0.9])\n",
    "\t\t\t\tgen_loss.append(g_loss)\n",
    "\n",
    "\t\t\t\tprint(f'Generator Loss: {g_loss}')\n",
    "\n",
    "\t\t\t\tif epoch % 5 == 0:\n",
    "\t\t\t\t\tlatent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
    "\t\t\t\t\tembedding_batch = high_test_embeds[0 : self.batch_size]\n",
    "\n",
    "\t\t\t\t\tlow_fake_images, _ = self.stage1_generator.predict([embedding_batch, latent_space], verbose=3)\n",
    "\t\t\t\t\thigh_fake_images, _ = self.stage2_generator.predict([embedding_batch, low_fake_images], verbose=3)\n",
    "\n",
    "\t\t\t\t\tfor i, image in enumerate(high_fake_images[:10]):\n",
    "\t\t\t\t\t    save_image(image, f'results_stage2/gen_{epoch}_{i}.png')\n",
    "\n",
    "\t\t\t\tif epoch % 10 == 0:\n",
    "\t\t\t\t\tself.stage2_generator.save_weights('weights/stage2_gen.h5')\n",
    "\t\t\t\t\tself.stage2_discriminator.save_weights(\"weights/stage2_disc.h5\")\n",
    "\t\t\t\t\tself.ca_network.save_weights('weights/stage2_ca.h5')\n",
    "\t\t\t\t\tself.embedding_compressor.save_weights('weights/stage2_embco.h5')\n",
    "\t\t\t\t\tself.stage2_adversarial.save_weights('weights/stage2_adv.h5')\n",
    "\n",
    "\t\tself.stage2_generator.save_weights('weights/stage2_gen.h5')\n",
    "\t\tself.stage2_discriminator.save_weights(\"weights/stage2_disc.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccda376",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2 = StackGanStage2()\n",
    "stage2.train_stage2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
